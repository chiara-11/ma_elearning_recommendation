{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content-based Recommendation\n",
    "\n",
    "This notebook executes the experiments for Content-based Recommendation, which is only performed without reference classes.\n",
    "\n",
    "The experiments are separated into 4 versions.\n",
    "\n",
    "Note: The code in this notebook for the different versions only differs by the conf dictionary used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../../sources'))\n",
    "\n",
    "import config\n",
    "import training_general\n",
    "import training_without_rc\n",
    "import utils\n",
    "from data_preparation import determine_reference_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "df = utils.read_data_file(\"final_data_main_approach.csv\")\n",
    "df_orig = df.copy()\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version 1: DTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conf_version1(filename_suffix: str) -> dict:\n",
    "    return {\n",
    "        \"lim\": [0.3, 0.5, 0.7, config.LimType.DYNAMIC],\n",
    "        \"eval_groups\": [\"info_cols\", \"reg_metrics\", \"class_metrics\"],\n",
    "        \"reg_metrics\": [config.RegMetrics.MAE, config.RegMetrics.MSE],\n",
    "        \"class_metrics\": [\n",
    "            config.ClassMetrics.ACC,\n",
    "            config.ClassMetrics.F1,\n",
    "            config.ClassMetrics.PREC,\n",
    "            config.ClassMetrics.REC,\n",
    "        ],\n",
    "        \"info_cols\": [\n",
    "            config.InfoCols.NUM_UT_PROBS,\n",
    "            config.InfoCols.NUM_IU_PROBS,\n",
    "            config.InfoCols.MEAN_UT_PERF,\n",
    "            config.InfoCols.MEAN_IU_PERF,\n",
    "        ],\n",
    "        \"method\": config.RecMethod.CB,\n",
    "        \"with_ref_class\": False,\n",
    "        \"models\": [\n",
    "            {\"model_type\": config.CBModelType.DTC, \"used_columns\": \"v1\"},\n",
    "            {\"model_type\": config.CBModelType.DTC, \"used_columns\": \"v1\", \"max_depth\": 3},\n",
    "            {\"model_type\": config.CBModelType.DTC, \"used_columns\": \"v2\"},\n",
    "            {\"model_type\": config.CBModelType.DTC, \"used_columns\": \"v2\", \"max_depth\": 3},\n",
    "        ],\n",
    "        \"saving_file\": {\n",
    "            \"folder\": \"content_based_recommendation\",\n",
    "            \"filename\": \"version1\",\n",
    "            \"filename_suffix\": filename_suffix,\n",
    "        },\n",
    "    }\n",
    "\n",
    "save_file = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = get_conf_version1(filename_suffix=\"\")\n",
    "\n",
    "df = df_orig.copy()\n",
    "\n",
    "# check validity of conf dictionary\n",
    "training_general.check_conf(conf, save_file=save_file)\n",
    "\n",
    "with_rc = conf[\"with_ref_class\"]\n",
    "\n",
    "# prepare df\n",
    "df = training_general.prepare_df(conf, df)\n",
    "\n",
    "# get dictionary with reference classes\n",
    "class_to_reference_class = determine_reference_classes.get_reference_classes(df)\n",
    "print(len(class_to_reference_class))\n",
    "# it is not used for the reference classes but to know which classes and test sequences are evaluated\n",
    "\n",
    "# create dataframes\n",
    "df, ass_seq, _ = training_general.create_dataframes(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty predictions dataframe for complete training\n",
    "if with_rc:\n",
    "    raise NotImplementedError\n",
    "else:\n",
    "    index = training_without_rc.get_idx_pred_df(class_to_reference_class)\n",
    "pred_df = training_general.initialize_pred_df(index=index, conf=conf)\n",
    "\n",
    "count = 0\n",
    "# count = 1550\n",
    "# for cid, cid_dict in list(class_to_reference_class.items())[:3]:\n",
    "for cid, cid_dict in class_to_reference_class.items():\n",
    "    # for cid in [\"2JFV80TTBO\"]:\n",
    "    # cid_dict = class_to_reference_class[cid]\n",
    "    # print(f\"----------- Class {cid} ------------\")\n",
    "\n",
    "    # make predictions for cid, evaluate and store evaluation results\n",
    "    if with_rc:\n",
    "        raise NotImplementedError\n",
    "    else:\n",
    "        pred_df.loc[cid] = (\n",
    "            training_without_rc.perform_predictions_for_cid(\n",
    "                conf, cid, cid_dict, df, ass_seq\n",
    "            )\n",
    "            .reindex(pred_df.loc[cid].index)\n",
    "            .to_numpy()\n",
    "        )\n",
    "\n",
    "    count += 1\n",
    "    if count % 10 == 0:\n",
    "        d = datetime.datetime.now()\n",
    "        print(f\"{count} classes completed, last cid: {cid}, time: {d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows only containing nans\n",
    "# only necessary if part of classes is trained\n",
    "pred_df = pred_df.dropna(subset=[\"y_true\"])\n",
    "print(len(pred_df))\n",
    "\n",
    "# save predictions\n",
    "utils.save_predictions(pred_df, conf, save_idx=True)\n",
    "\n",
    "# evaluate predictions and save\n",
    "training_general.evaluate_predictions_and_save(pred_df, conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version 2: KNN, LinReg, SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conf_version2(filename_suffix: str) -> dict:\n",
    "    return {\n",
    "        \"lim\": [0.3, 0.5, 0.7, config.LimType.DYNAMIC],\n",
    "        \"eval_groups\": [\"info_cols\", \"reg_metrics\", \"class_metrics\"],\n",
    "        \"reg_metrics\": [config.RegMetrics.MAE, config.RegMetrics.MSE],\n",
    "        \"class_metrics\": [\n",
    "            config.ClassMetrics.ACC,\n",
    "            config.ClassMetrics.F1,\n",
    "            config.ClassMetrics.PREC,\n",
    "            config.ClassMetrics.REC,\n",
    "        ],\n",
    "        \"info_cols\": [\n",
    "            config.InfoCols.NUM_UT_PROBS,\n",
    "            config.InfoCols.NUM_IU_PROBS,\n",
    "            config.InfoCols.MEAN_UT_PERF,\n",
    "            config.InfoCols.MEAN_IU_PERF,\n",
    "        ],\n",
    "        \"method\": config.RecMethod.CB,\n",
    "        \"with_ref_class\": False,\n",
    "        \"models\": [\n",
    "            {\"model_type\": config.CBModelType.KNN, \"used_columns\": \"v2\", \"k\": 3},\n",
    "            {\"model_type\": config.CBModelType.KNN, \"used_columns\": \"v2\", \"k\": 5},\n",
    "            {\"model_type\": config.CBModelType.LINREG, \"used_columns\": \"v1\"},\n",
    "            {\"model_type\": config.CBModelType.LINREG, \"used_columns\": \"v2\"},\n",
    "            {\"model_type\": config.CBModelType.SVC, \"used_columns\": \"v2\"},\n",
    "        ],\n",
    "        \"saving_file\": {\n",
    "            \"folder\": \"content_based_recommendation\",\n",
    "            \"filename\": \"version2\",\n",
    "            \"filename_suffix\": filename_suffix,\n",
    "        },\n",
    "    }\n",
    "\n",
    "save_file = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = get_conf_version2(filename_suffix=\"\")\n",
    "\n",
    "df = df_orig.copy()\n",
    "\n",
    "# check validity of conf dictionary\n",
    "training_general.check_conf(conf, save_file=save_file)\n",
    "\n",
    "with_rc = conf[\"with_ref_class\"]\n",
    "\n",
    "# prepare df\n",
    "df = training_general.prepare_df(conf, df)\n",
    "\n",
    "# get dictionary with reference classes\n",
    "class_to_reference_class = determine_reference_classes.get_reference_classes(df)\n",
    "print(len(class_to_reference_class))\n",
    "# it is not used for the reference classes but to know which classes and test sequences are evaluated\n",
    "\n",
    "# create dataframes\n",
    "df, ass_seq, _ = training_general.create_dataframes(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty predictions dataframe for complete training\n",
    "if with_rc:\n",
    "    raise NotImplementedError\n",
    "else:\n",
    "    index = training_without_rc.get_idx_pred_df(class_to_reference_class)\n",
    "pred_df = training_general.initialize_pred_df(index=index, conf=conf)\n",
    "\n",
    "count = 0\n",
    "# count = 1550\n",
    "# for cid, cid_dict in list(class_to_reference_class.items())[:30]:\n",
    "for cid, cid_dict in class_to_reference_class.items():\n",
    "    # for cid in [\"EGEHUE9HG\"]:\n",
    "    # cid_dict = class_to_reference_class[cid]\n",
    "    # print(f\"----------- Class {cid} ------------\")\n",
    "\n",
    "    # make predictions for cid, evaluate and store evaluation results\n",
    "    if with_rc:\n",
    "        raise NotImplementedError\n",
    "    else:\n",
    "        pred_df.loc[cid] = (\n",
    "            training_without_rc.perform_predictions_for_cid(\n",
    "                conf, cid, cid_dict, df, ass_seq\n",
    "            )\n",
    "            .reindex(pred_df.loc[cid].index)\n",
    "            .to_numpy()\n",
    "        )\n",
    "\n",
    "    count += 1\n",
    "    if count % 10 == 0:\n",
    "        d = datetime.datetime.now()\n",
    "        print(f\"{count} classes completed, last cid: {cid}, time: {d}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows only containing nans\n",
    "# only necessary if part of classes is trained\n",
    "pred_df = pred_df.dropna(subset=[\"y_true\"])\n",
    "print(len(pred_df))\n",
    "\n",
    "# save predictions\n",
    "utils.save_predictions(pred_df, conf, save_idx=True)\n",
    "\n",
    "# evaluate predictions and save\n",
    "training_general.evaluate_predictions_and_save(pred_df, conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version 3: RFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conf_version3(filename_suffix: str) -> dict:\n",
    "    return {\n",
    "        \"lim\": [0.3, 0.5, 0.7, config.LimType.DYNAMIC],\n",
    "        \"eval_groups\": [\"info_cols\", \"reg_metrics\", \"class_metrics\"],\n",
    "        \"reg_metrics\": [config.RegMetrics.MAE, config.RegMetrics.MSE],\n",
    "        \"class_metrics\": [\n",
    "            config.ClassMetrics.ACC,\n",
    "            config.ClassMetrics.F1,\n",
    "            config.ClassMetrics.PREC,\n",
    "            config.ClassMetrics.REC,\n",
    "        ],\n",
    "        \"info_cols\": [\n",
    "            config.InfoCols.NUM_UT_PROBS,\n",
    "            config.InfoCols.NUM_IU_PROBS,\n",
    "            config.InfoCols.MEAN_UT_PERF,\n",
    "            config.InfoCols.MEAN_IU_PERF,\n",
    "        ],\n",
    "        \"method\": config.RecMethod.CB,\n",
    "        \"with_ref_class\": False,\n",
    "        \"models\": [\n",
    "            {\"model_type\": config.CBModelType.RFC, \"used_columns\": \"v1\", \"n_estimators\": 10},\n",
    "            {\"model_type\": config.CBModelType.RFC, \"used_columns\": \"v1\", \"n_estimators\": 25},\n",
    "            {\"model_type\": config.CBModelType.RFC, \"used_columns\": \"v2\", \"n_estimators\": 10},\n",
    "            {\"model_type\": config.CBModelType.RFC, \"used_columns\": \"v2\", \"n_estimators\": 25},\n",
    "            {\"model_type\": config.CBModelType.RFC, \"used_columns\": \"v2\", \"n_estimators\": 10, \"max_depth\": 3},\n",
    "            {\"model_type\": config.CBModelType.RFC, \"used_columns\": \"v2\", \"n_estimators\": 25, \"max_depth\": 3},\n",
    "        ],\n",
    "        \"saving_file\": {\n",
    "            \"folder\": \"content_based_recommendation\",\n",
    "            \"filename\": \"version3\",\n",
    "            \"filename_suffix\": filename_suffix,\n",
    "        },\n",
    "    }\n",
    "\n",
    "save_file = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = get_conf_version3(filename_suffix=\"\")\n",
    "\n",
    "df = df_orig.copy()\n",
    "\n",
    "# check validity of conf dictionary\n",
    "training_general.check_conf(conf, save_file=save_file)\n",
    "\n",
    "with_rc = conf[\"with_ref_class\"]\n",
    "\n",
    "# prepare df\n",
    "df = training_general.prepare_df(conf, df)\n",
    "\n",
    "# get dictionary with reference classes\n",
    "class_to_reference_class = determine_reference_classes.get_reference_classes(df)\n",
    "print(len(class_to_reference_class))\n",
    "# it is not used for the reference classes but to know which classes and test sequences are evaluated\n",
    "\n",
    "# create dataframes\n",
    "df, ass_seq, _ = training_general.create_dataframes(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty predictions dataframe for complete training\n",
    "if with_rc:\n",
    "    raise NotImplementedError\n",
    "else:\n",
    "    index = training_without_rc.get_idx_pred_df(class_to_reference_class)\n",
    "pred_df = training_general.initialize_pred_df(index=index, conf=conf)\n",
    "\n",
    "\n",
    "count = 0\n",
    "#count = 1550\n",
    "#for cid, cid_dict in list(class_to_reference_class.items())[:3]:\n",
    "for cid, cid_dict in class_to_reference_class.items():\n",
    "#for cid in [\"2JFV80TTBO\"]:\n",
    "    #cid_dict = class_to_reference_class[cid]\n",
    "    #print(f\"----------- Class {cid} ------------\")\n",
    "\n",
    "    # make predictions for cid, evaluate and store evaluation results\n",
    "    if with_rc:\n",
    "        raise NotImplementedError\n",
    "    else:\n",
    "        pred_df.loc[cid] = (\n",
    "            training_without_rc.perform_predictions_for_cid(\n",
    "            conf, cid, cid_dict, df, ass_seq\n",
    "        )\n",
    "        .reindex(pred_df.loc[cid].index)\n",
    "        .to_numpy()\n",
    "    )\n",
    "    \n",
    "    count += 1\n",
    "    if count % 10 == 0:\n",
    "        d = datetime.datetime.now()\n",
    "        print(f\"{count} classes completed, last cid: {cid}, time: {d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows only containing nans\n",
    "# only necessary if part of classes is trained\n",
    "pred_df = pred_df.dropna(subset=[\"y_true\"])\n",
    "print(len(pred_df))\n",
    "\n",
    "# save predictions\n",
    "utils.save_predictions(pred_df, conf, save_idx=True)\n",
    "\n",
    "# evaluate predictions and save\n",
    "training_general.evaluate_predictions_and_save(pred_df, conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version 4: LogReg and XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conf_version4(filename_suffix: str) -> dict:\n",
    "    return {\n",
    "        \"lim\": [0.3, 0.5, 0.7, config.LimType.DYNAMIC],\n",
    "        \"eval_groups\": [\"info_cols\", \"reg_metrics\", \"class_metrics\"],\n",
    "        \"reg_metrics\": [config.RegMetrics.MAE, config.RegMetrics.MSE],\n",
    "        \"class_metrics\": [\n",
    "            config.ClassMetrics.ACC,\n",
    "            config.ClassMetrics.F1,\n",
    "            config.ClassMetrics.PREC,\n",
    "            config.ClassMetrics.REC,\n",
    "        ],\n",
    "        \"info_cols\": [\n",
    "            config.InfoCols.NUM_UT_PROBS,\n",
    "            config.InfoCols.NUM_IU_PROBS,\n",
    "            config.InfoCols.MEAN_UT_PERF,\n",
    "            config.InfoCols.MEAN_IU_PERF,\n",
    "        ],\n",
    "        \"method\": config.RecMethod.CB,\n",
    "        \"with_ref_class\": False,\n",
    "        \"models\": [\n",
    "            {\"model_type\": config.CBModelType.LOGREG, \"used_columns\": \"v2\", \"max_iter\": 100},\n",
    "            {\"model_type\": config.CBModelType.LOGREG, \"used_columns\": \"v2\", \"max_iter\": 300},\n",
    "            {\"model_type\": config.CBModelType.XGB, \"used_columns\": \"v1\", \"n_estimators\": 50, \"max_depth\": 5, \"lr\": 0.1},\n",
    "            {\"model_type\": config.CBModelType.XGB, \"used_columns\": \"v1\", \"n_estimators\": 25, \"max_depth\": 3, \"lr\": 0.1},\n",
    "            {\"model_type\": config.CBModelType.XGB, \"used_columns\": \"v2\", \"n_estimators\": 50, \"max_depth\": 3, \"lr\": 0.1},\n",
    "            {\"model_type\": config.CBModelType.XGB, \"used_columns\": \"v2\", \"n_estimators\": 25, \"max_depth\": 3, \"lr\": 0.01}\n",
    "        ],\n",
    "        \"saving_file\": {\n",
    "            \"folder\": \"content_based_recommendation\",\n",
    "            \"filename\": \"version4\",\n",
    "            \"filename_suffix\": filename_suffix,\n",
    "        },\n",
    "    }\n",
    "\n",
    "save_file = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = get_conf_version4(filename_suffix=\"\")\n",
    "\n",
    "df = df_orig.copy()\n",
    "\n",
    "# check validity of conf dictionary\n",
    "training_general.check_conf(conf, save_file=save_file)\n",
    "\n",
    "with_rc = conf[\"with_ref_class\"]\n",
    "\n",
    "# prepare df\n",
    "df = training_general.prepare_df(conf, df)\n",
    "\n",
    "# get dictionary with reference classes\n",
    "class_to_reference_class = determine_reference_classes.get_reference_classes(df)\n",
    "print(len(class_to_reference_class))\n",
    "# it is not used for the reference classes but to know which classes and test sequences are evaluated\n",
    "\n",
    "# create dataframes\n",
    "df, ass_seq, _ = training_general.create_dataframes(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty predictions dataframe for complete training\n",
    "if with_rc:\n",
    "    raise NotImplementedError\n",
    "else:\n",
    "    index = training_without_rc.get_idx_pred_df(class_to_reference_class)\n",
    "pred_df = training_general.initialize_pred_df(index=index, conf=conf)\n",
    "\n",
    "\n",
    "count = 0\n",
    "#count = 1550\n",
    "#for cid, cid_dict in list(class_to_reference_class.items())[:5]:\n",
    "for cid, cid_dict in class_to_reference_class.items():\n",
    "#for cid in [\"2JFV80TTBO\"]:\n",
    "    #cid_dict = class_to_reference_class[cid]\n",
    "    # print(f\"----------- Class {cid} ------------\")\n",
    "\n",
    "    # make predictions for cid, evaluate and store evaluation results\n",
    "    if with_rc:\n",
    "        raise NotImplementedError\n",
    "    else:\n",
    "        pred_df.loc[cid] = (\n",
    "            training_without_rc.perform_predictions_for_cid(\n",
    "            conf, cid, cid_dict, df, ass_seq\n",
    "        )\n",
    "        .reindex(pred_df.loc[cid].index)\n",
    "        .to_numpy()\n",
    "    )\n",
    "    \n",
    "    count += 1\n",
    "    if count % 10 == 0:\n",
    "        d = datetime.datetime.now()\n",
    "        print(f\"{count} classes completed, last cid: {cid}, time: {d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows only containing nans\n",
    "# only necessary if part of classes is trained\n",
    "pred_df = pred_df.dropna(subset=[\"y_true\"])\n",
    "print(len(pred_df))\n",
    "\n",
    "# save predictions\n",
    "utils.save_predictions(pred_df, conf, save_idx=True)\n",
    "\n",
    "# evaluate predictions and save\n",
    "training_general.evaluate_predictions_and_save(pred_df, conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
