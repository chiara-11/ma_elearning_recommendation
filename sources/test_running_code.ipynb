{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Running Code in this Repo\n",
    "\n",
    "This file is set up to test if running code in this repo works, particularly if all data required for the individual steps is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chiara\\AppData\\Local\\Temp\\ipykernel_10900\\1385273033.py:5: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "c:\\Users\\Chiara\\Documents\\Uni_Master_MMDS\\Masterarbeit\\ma_elearning_recommendation\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../sources'))\n",
    "\n",
    "import config\n",
    "import training_general\n",
    "import training_without_rc\n",
    "import utils\n",
    "from data_preparation import determine_reference_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test General Functionality\n",
    "\n",
    "Only the data already stored in the `data` folder is necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29813\n"
     ]
    }
   ],
   "source": [
    "# test if data for executing the code in general is available\n",
    "expert_bkt_probs = utils.read_data_file(\"expert_data_bkt_probs.csv\")\n",
    "print(len(expert_bkt_probs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Files for Data Preparation\n",
    "\n",
    "For executing the notebooks in `data_preparation`, all data files should be downloaded from https://www.kaggle.com/competitions/edm-cup-2023/data and stored in the `data` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132738\n"
     ]
    }
   ],
   "source": [
    "# test if data for executing the code in general is available\n",
    "df = utils.read_problem_details()\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Executing Experiments\n",
    "\n",
    "The file `final_data_main_approach.csv` should be downloaded from the Google Drive folder and stored in the `data` folder.\n",
    "\n",
    "This additionally requires the following files from https://www.kaggle.com/competitions/edm-cup-2023/data to be stored in the `data` folder:\n",
    "- `assignment_relationships.csv`\n",
    "- `problem_details.csv`\n",
    "- `sequence_details.csv`\n",
    "\n",
    "In addition, make sure to create a folder `results` at the same level as the `data` folder and inside this folder another folder `content_based_recommendation`.\n",
    "\n",
    "This step takes approx. 1 minute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chiara\\Documents\\Uni_Master_MMDS\\Masterarbeit\\ma_elearning_recommendation\\sources\\utils.py:15: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  return pd.read_csv(config.DATA_FOLDER / filename)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2664573, 22)\n"
     ]
    }
   ],
   "source": [
    "# read data\n",
    "df = utils.read_data_file(\"final_data_main_approach.csv\")\n",
    "df_orig = df.copy()\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conf_version1(filename_suffix: str) -> dict:\n",
    "    return {\n",
    "        \"lim\": [0.5],\n",
    "        \"eval_groups\": [\"info_cols\", \"class_metrics\"],\n",
    "        \"reg_metrics\": [],\n",
    "        \"class_metrics\": [\n",
    "            config.ClassMetrics.ACC,\n",
    "            config.ClassMetrics.F1,\n",
    "        ],\n",
    "        \"info_cols\": [\n",
    "            config.InfoCols.NUM_UT_PROBS,\n",
    "            config.InfoCols.NUM_IU_PROBS,\n",
    "            config.InfoCols.MEAN_UT_PERF,\n",
    "            config.InfoCols.MEAN_IU_PERF,\n",
    "        ],\n",
    "        \"method\": config.RecMethod.CB,\n",
    "        \"with_ref_class\": False,\n",
    "        \"models\": [\n",
    "            {\"model_type\": config.CBModelType.DTC, \"used_columns\": \"v1\"},\n",
    "        ],\n",
    "        \"saving_file\": {\n",
    "            \"folder\": \"content_based_recommendation\",\n",
    "            \"filename\": \"test_file\",\n",
    "            \"filename_suffix\": filename_suffix,\n",
    "        },\n",
    "    }\n",
    "\n",
    "save_file = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1523\n"
     ]
    }
   ],
   "source": [
    "conf = get_conf_version1(filename_suffix=\"test_code\")\n",
    "\n",
    "df = df_orig.copy()\n",
    "\n",
    "# check validity of conf dictionary\n",
    "training_general.check_conf(conf, save_file=save_file)\n",
    "\n",
    "with_rc = conf[\"with_ref_class\"]\n",
    "\n",
    "# prepare df\n",
    "df = training_general.prepare_df(conf, df)\n",
    "\n",
    "# get dictionary with reference classes\n",
    "class_to_reference_class = determine_reference_classes.get_reference_classes(df)\n",
    "print(len(class_to_reference_class))\n",
    "# it is not used for the reference classes but to know which classes and test sequences are evaluated\n",
    "\n",
    "# create dataframes\n",
    "df, ass_seq, _ = training_general.create_dataframes(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- Class 2JFV80TTBO ------------\n",
      "----------- Class C4EIV9P0E ------------\n",
      "----------- Class EGEHUE9HG ------------\n",
      "----------- Class 1FN3UGSKCC ------------\n",
      "----------- Class D3EXBNF3N ------------\n"
     ]
    }
   ],
   "source": [
    "# create empty predictions dataframe for complete training\n",
    "if with_rc:\n",
    "    raise NotImplementedError\n",
    "else:\n",
    "    index = training_without_rc.get_idx_pred_df(class_to_reference_class)\n",
    "pred_df = training_general.initialize_pred_df(index=index, conf=conf)\n",
    "\n",
    "count = 0\n",
    "for cid, cid_dict in list(class_to_reference_class.items())[:5]:\n",
    "    print(f\"----------- Class {cid} ------------\")\n",
    "    # make predictions for cid, evaluate and store evaluation results\n",
    "    if with_rc:\n",
    "        raise NotImplementedError\n",
    "    else:\n",
    "        pred_df.loc[cid] = (\n",
    "            training_without_rc.perform_predictions_for_cid(\n",
    "                conf, cid, cid_dict, df, ass_seq\n",
    "            )\n",
    "            .reindex(pred_df.loc[cid].index)\n",
    "            .to_numpy()\n",
    "        )\n",
    "\n",
    "    count += 1\n",
    "    if count % 10 == 0:\n",
    "        d = datetime.datetime.now()\n",
    "        print(f\"{count} classes completed, last cid: {cid}, time: {d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76\n",
      "Start evaluating dtc_used_columns_v1 (2024-09-02 09:59:54.056966)\n",
      "Saved evaluation df with filename dtc_used_columns_v1_test_code_20240902_095954.csv in folder content_based_recommendation\n"
     ]
    }
   ],
   "source": [
    "# drop rows only containing nans\n",
    "# only necessary if part of classes is trained\n",
    "pred_df = pred_df.dropna(subset=[\"y_true\"])\n",
    "print(len(pred_df))\n",
    "\n",
    "# save predictions\n",
    "#utils.save_predictions(pred_df, conf, save_idx=True)\n",
    "\n",
    "# evaluate predictions and save\n",
    "training_general.evaluate_predictions_and_save(pred_df, conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Reading Results Files\n",
    "\n",
    "For testing this part, you have two options:\n",
    "1. You can run the part before `Test Executing Experiments` which will automatically store results files in the `results` folder.\n",
    "In this case, run the cell belonging to \"Option 1\".\n",
    "2. Alternatively, the content of the result folder must be downloaded from Google Drive and stored in a folder `results` at the same level as the `data` folder. The `results` folder should follow the same structure as the respective folder at Google Drive, containing five folders, one for each method type.\n",
    "For executing the cells below it is particularly required to store the file `results\\content_based_recommendation\\dtc_used_columns_v1_20240804_194156.csv`.\n",
    "In this case, run the cell belonging to \"Option 2\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dtc_used_columns_v1\n",
      "Read file dtc_used_columns_v1_test_code_20240902_095954.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test reading results - Option 1\n",
    "folder = \"content_based_recommendation\"\n",
    "model = {\"model_type\": config.CBModelType.DTC, \"used_columns\": \"v1\"}\n",
    "model_name = training_general.build_model_name(model)\n",
    "print(model_name)\n",
    "\n",
    "suff = \"test_code\"\n",
    "\n",
    "eval_df = utils.read_evaluation_df(folder, f\"{model_name}_{suff}\", latest=True)\n",
    "len(eval_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dtc_used_columns_v1\n",
      "Read file dtc_used_columns_v1_20240804_194156.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "30580"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test reading results - Option 2\n",
    "folder = \"content_based_recommendation\"\n",
    "model = {\"model_type\": config.CBModelType.DTC, \"used_columns\": \"v1\"}\n",
    "model_name = training_general.build_model_name(model)\n",
    "print(model_name)\n",
    "\n",
    "eval_df = utils.read_evaluation_df(folder, model_name, latest=True)\n",
    "len(eval_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
