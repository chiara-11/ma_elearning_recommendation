{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Item Response Theory\n",
    "\n",
    "This notebook executes the experiments for Item Response Theory, which is performed both with and without reference classes.\n",
    "\n",
    "The experiments for WRC are separated into 3 versions (1, 3, 4).\n",
    "The experiments for WORC are all performed in version 2.\n",
    "\n",
    "Note: The code in this notebook for the different versions and parts only differs by the specified class-to-reference-class dictionary and the conf dictionary used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../../sources'))\n",
    "\n",
    "import config\n",
    "import utils\n",
    "import training_general\n",
    "import training_with_rc\n",
    "import training_without_rc\n",
    "from data_preparation import determine_reference_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WITH REFERENCE CLASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "df = utils.read_data_file(\"final_data_main_approach.csv\")\n",
    "df_orig = df.copy()\n",
    "print(df.shape)\n",
    "\n",
    "# get dictionary with reference classes\n",
    "class_to_reference_class = determine_reference_classes.get_reference_classes(df)\n",
    "\n",
    "# uncomment when executing version 4\n",
    "#class_to_reference_class = determine_reference_classes.restrict_c2rc_dict(\n",
    "#    class_to_reference_class, \"ref_classes_restricted.csv\"\n",
    "#)\n",
    "\n",
    "# uncomment when executing version 3\n",
    "#class_to_reference_class = determine_reference_classes.restrict_c2rc_dict(\n",
    "#    class_to_reference_class, \"ref_classes_restricted_random.csv\"\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate class_to_reference_class in 4 parts\n",
    "cut1 = 350\n",
    "cut2 = 600\n",
    "cut3 = 1050\n",
    "c2rc_part1 = {k: v for k, v in list(class_to_reference_class.items())[:cut1]}\n",
    "c2rc_part2 = {k: v for k, v in list(class_to_reference_class.items())[cut1:cut2]}\n",
    "c2rc_part3 = {k: v for k, v in list(class_to_reference_class.items())[cut2:cut3]}\n",
    "c2rc_part4 = {k: v for k, v in list(class_to_reference_class.items())[cut3:]}\n",
    "print(len(c2rc_part1), len(c2rc_part2), len(c2rc_part3), len(c2rc_part4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version 1: mean / mean --> all reference classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conf_version1(filename_suffix: str) -> dict:\n",
    "    return {\n",
    "        \"lim\": [0.3, 0.5, 0.7, config.LimType.DYNAMIC],\n",
    "        \"eval_groups\": [\"info_cols\", \"reg_metrics\", \"class_metrics\"],\n",
    "        \"reg_metrics\": [config.RegMetrics.MAE, config.RegMetrics.MSE],\n",
    "        \"class_metrics\": [\n",
    "            config.ClassMetrics.ACC,\n",
    "            config.ClassMetrics.F1,\n",
    "            config.ClassMetrics.PREC,\n",
    "            config.ClassMetrics.REC,\n",
    "        ],\n",
    "        \"info_cols\": [\n",
    "            config.InfoCols.NUM_UT_PROBS,\n",
    "            config.InfoCols.NUM_IU_PROBS,\n",
    "            config.InfoCols.MEAN_UT_PERF,\n",
    "            config.InfoCols.MEAN_IU_PERF,\n",
    "            config.InfoCols.NUM_STUD_RC,\n",
    "            config.InfoCols.MAX_NUM_IU_PROBS_RC,\n",
    "            config.InfoCols.MEAN_IU_PERF_RC,\n",
    "            config.InfoCols.MEAN_UT_PERF_RC\n",
    "        ],\n",
    "        \"method\": config.RecMethod.IRT,\n",
    "        \"with_ref_class\": True,\n",
    "        \"models\": [\n",
    "            {\n",
    "                \"model_type\": config.IRTModelType.WRC,\n",
    "                \"ability\": \"mean\",\n",
    "                \"difficulty\": \"mean\",\n",
    "            },\n",
    "            {\n",
    "                \"model_type\": config.IRTModelType.WRC,\n",
    "                \"ability\": \"mean\",\n",
    "                \"ab_int\": 3,\n",
    "                \"difficulty\": \"mean\",\n",
    "                \"diff_int\": 3,\n",
    "            },\n",
    "            {\n",
    "                \"model_type\": config.IRTModelType.WRC,\n",
    "                \"ability\": \"mean\",\n",
    "                \"ab_int\": 3,\n",
    "                \"difficulty\": \"mean\",\n",
    "            },\n",
    "            {\n",
    "                \"model_type\": config.IRTModelType.WRC,\n",
    "                \"ability\": \"mean\",\n",
    "                \"difficulty\": \"mean\",\n",
    "                \"diff_int\": 3,\n",
    "            },\n",
    "        ],\n",
    "        \"saving_file\": {\n",
    "            \"folder\": \"item_response_theory\",\n",
    "            \"filename\": \"version1\",\n",
    "            \"filename_suffix\": filename_suffix,\n",
    "        },\n",
    "    }\n",
    "\n",
    "save_file = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2rc = c2rc_part1.copy()\n",
    "df = df_orig.copy()\n",
    "\n",
    "conf = get_conf_version1(filename_suffix=\"part1\")\n",
    "\n",
    "# check validity of conf dictionary\n",
    "training_general.check_conf(conf, save_file=save_file)\n",
    "\n",
    "with_rc = conf[\"with_ref_class\"]\n",
    "\n",
    "# create dataframes\n",
    "df, ass_seq, stud_per_class = training_general.create_dataframes(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty evaluation dataframe for complete training\n",
    "if with_rc:\n",
    "    index = training_with_rc.get_idx_pred_df(c2rc)\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "pred_df = training_general.initialize_pred_df(index=index, conf=conf)\n",
    "\n",
    "\n",
    "count = 0\n",
    "#count = 320\n",
    "for cid, cid_dict in c2rc.items():\n",
    "#for cid, cid_dict in list(c2rc.items())[:1]:\n",
    "#for cid in [\"ODWI4QBKV\"]:\n",
    "    #cid_dict = c2rc[cid]\n",
    "    #print(f\"----------- Class {cid} ------------\")\n",
    "\n",
    "    # make predictions for cid, evaluate and store evaluation results\n",
    "    if with_rc:\n",
    "        pred_df.loc[cid] = (\n",
    "            training_with_rc.perform_predictions_for_cid(\n",
    "                conf, cid, cid_dict, df, ass_seq, stud_per_class\n",
    "            )\n",
    "            .reindex(pred_df.loc[cid].index)\n",
    "            .to_numpy()\n",
    "        )\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    count += 1\n",
    "    if count % 10 == 0:\n",
    "        d = datetime.datetime.now()\n",
    "        print(f\"{count} classes completed, last cid: {cid}, time: {d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows only containing nans\n",
    "pred_df = pred_df.dropna(subset=[\"y_true\"])\n",
    "print(len(pred_df))\n",
    "pred_df1 = pred_df.copy()\n",
    "\n",
    "# save\n",
    "utils.save_predictions(pred_df, conf, save_idx=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pred_df1.copy()\n",
    "# evaluate predictions and save\n",
    "training_general.evaluate_predictions_and_save(pred_df, conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2rc = c2rc_part2.copy()\n",
    "df = df_orig.copy()\n",
    "\n",
    "conf = get_conf_version1(filename_suffix=\"part2\")\n",
    "\n",
    "# check validity of conf dictionary\n",
    "training_general.check_conf(conf, save_file=save_file)\n",
    "\n",
    "with_rc = conf[\"with_ref_class\"]\n",
    "\n",
    "# create dataframes\n",
    "df, ass_seq, stud_per_class = training_general.create_dataframes(df)\n",
    "\n",
    "# create empty evaluation dataframe for complete training\n",
    "if with_rc:\n",
    "    index = training_with_rc.get_idx_pred_df(c2rc)\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "pred_df = training_general.initialize_pred_df(index=index, conf=conf)\n",
    "\n",
    "\n",
    "count = 0\n",
    "#count = 320\n",
    "for cid, cid_dict in c2rc.items():\n",
    "#for cid, cid_dict in list(c2rc.items())[:3]:\n",
    "#for cid in [\"ODWI4QBKV\"]:\n",
    "    #cid_dict = c2rc[cid]\n",
    "    #print(f\"----------- Class {cid} ------------\")\n",
    "\n",
    "    # make predictions for cid, evaluate and store evaluation results\n",
    "    if with_rc:\n",
    "        pred_df.loc[cid] = (\n",
    "            training_with_rc.perform_predictions_for_cid(\n",
    "                conf, cid, cid_dict, df, ass_seq, stud_per_class\n",
    "            )\n",
    "            .reindex(pred_df.loc[cid].index)\n",
    "            .to_numpy()\n",
    "        )\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    count += 1\n",
    "    if count % 10 == 0:\n",
    "        d = datetime.datetime.now()\n",
    "        print(f\"{count} classes completed, last cid: {cid}, time: {d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows only containing nans\n",
    "pred_df = pred_df.dropna(subset=[\"y_true\"])\n",
    "print(len(pred_df))\n",
    "pred_df2 = pred_df.copy()\n",
    "\n",
    "# save\n",
    "utils.save_predictions(pred_df, conf, save_idx=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pred_df2.copy()\n",
    "# evaluate predictions and save\n",
    "training_general.evaluate_predictions_and_save(pred_df, conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2rc = c2rc_part3.copy()\n",
    "df = df_orig.copy()\n",
    "\n",
    "conf = get_conf_version1(filename_suffix=\"part3\")\n",
    "\n",
    "# check validity of conf dictionary\n",
    "training_general.check_conf(conf, save_file=save_file)\n",
    "\n",
    "with_rc = conf[\"with_ref_class\"]\n",
    "\n",
    "# create dataframes\n",
    "df, ass_seq, stud_per_class = training_general.create_dataframes(df)\n",
    "\n",
    "# create empty evaluation dataframe for complete training\n",
    "if with_rc:\n",
    "    index = training_with_rc.get_idx_pred_df(c2rc)\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "pred_df = training_general.initialize_pred_df(index=index, conf=conf)\n",
    "\n",
    "\n",
    "count = 0\n",
    "#count = 320\n",
    "for cid, cid_dict in c2rc.items():\n",
    "#for cid, cid_dict in list(c2rc.items())[:3]:\n",
    "#for cid in [\"ODWI4QBKV\"]:\n",
    "    #cid_dict = c2rc[cid]\n",
    "    #print(f\"----------- Class {cid} ------------\")\n",
    "\n",
    "    # make predictions for cid, evaluate and store evaluation results\n",
    "    if with_rc:\n",
    "        pred_df.loc[cid] = (\n",
    "            training_with_rc.perform_predictions_for_cid(\n",
    "                conf, cid, cid_dict, df, ass_seq, stud_per_class\n",
    "            )\n",
    "            .reindex(pred_df.loc[cid].index)\n",
    "            .to_numpy()\n",
    "        )\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    count += 1\n",
    "    if count % 10 == 0:\n",
    "        d = datetime.datetime.now()\n",
    "        print(f\"{count} classes completed, last cid: {cid}, time: {d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows only containing nans\n",
    "pred_df = pred_df.dropna(subset=[\"y_true\"])\n",
    "print(len(pred_df))\n",
    "pred_df3 = pred_df.copy()\n",
    "\n",
    "# save\n",
    "utils.save_predictions(pred_df, conf, save_idx=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pred_df3.copy()\n",
    "# evaluate predictions and save\n",
    "training_general.evaluate_predictions_and_save(pred_df, conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Part 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2rc = c2rc_part4.copy()\n",
    "df = df_orig.copy()\n",
    "\n",
    "conf = get_conf_version1(filename_suffix=\"part4\")\n",
    "\n",
    "# check validity of conf dictionary\n",
    "training_general.check_conf(conf, save_file=save_file)\n",
    "\n",
    "with_rc = conf[\"with_ref_class\"]\n",
    "\n",
    "# create dataframes\n",
    "df, ass_seq, stud_per_class = training_general.create_dataframes(df)\n",
    "\n",
    "# create empty evaluation dataframe for complete training\n",
    "if with_rc:\n",
    "    index = training_with_rc.get_idx_pred_df(c2rc)\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "pred_df = training_general.initialize_pred_df(index=index, conf=conf)\n",
    "\n",
    "\n",
    "count = 0\n",
    "#count = 320\n",
    "for cid, cid_dict in c2rc.items():\n",
    "#for cid, cid_dict in list(c2rc.items())[:3]:\n",
    "#for cid in [\"ODWI4QBKV\"]:\n",
    "    #cid_dict = c2rc[cid]\n",
    "    #print(f\"----------- Class {cid} ------------\")\n",
    "\n",
    "    # make predictions for cid, evaluate and store evaluation results\n",
    "    if with_rc:\n",
    "        pred_df.loc[cid] = (\n",
    "            training_with_rc.perform_predictions_for_cid(\n",
    "                conf, cid, cid_dict, df, ass_seq, stud_per_class\n",
    "            )\n",
    "            .reindex(pred_df.loc[cid].index)\n",
    "            .to_numpy()\n",
    "        )\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    count += 1\n",
    "    if count % 10 == 0:\n",
    "        d = datetime.datetime.now()\n",
    "        print(f\"{count} classes completed, last cid: {cid}, time: {d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows only containing nans\n",
    "pred_df = pred_df.dropna(subset=[\"y_true\"])\n",
    "print(len(pred_df))\n",
    "pred_df4 = pred_df.copy()\n",
    "\n",
    "# save\n",
    "utils.save_predictions(pred_df, conf, save_idx=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pred_df4.copy()\n",
    "# evaluate predictions and save\n",
    "training_general.evaluate_predictions_and_save(pred_df, conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version 4: Proportion Correct and Elo --> restricted reference classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conf_version4(filename_suffix: str) -> dict:\n",
    "    return {\n",
    "        \"lim\": [0.5],\n",
    "        #\"lim\": [0.3, 0.5, 0.7, config.LimType.DYNAMIC],\n",
    "        \"eval_groups\": [\"info_cols\", \"reg_metrics\", \"class_metrics\"],\n",
    "        \"reg_metrics\": [config.RegMetrics.MAE, config.RegMetrics.MSE],\n",
    "        \"class_metrics\": [\n",
    "            config.ClassMetrics.ACC,\n",
    "            config.ClassMetrics.F1,\n",
    "            config.ClassMetrics.PREC,\n",
    "            config.ClassMetrics.REC,\n",
    "        ],\n",
    "        \"info_cols\": [\n",
    "            config.InfoCols.NUM_UT_PROBS,\n",
    "            config.InfoCols.NUM_IU_PROBS,\n",
    "            config.InfoCols.MEAN_UT_PERF,\n",
    "            config.InfoCols.MEAN_IU_PERF,\n",
    "            config.InfoCols.NUM_STUD_RC,\n",
    "            config.InfoCols.MAX_NUM_IU_PROBS_RC,\n",
    "            config.InfoCols.MEAN_IU_PERF_RC,\n",
    "            config.InfoCols.MEAN_UT_PERF_RC\n",
    "        ],\n",
    "        \"method\": config.RecMethod.IRT,\n",
    "        \"with_ref_class\": True,\n",
    "        \"models\": [\n",
    "            {\n",
    "                \"model_type\": config.IRTModelType.WRC,\n",
    "                \"ability\": \"mean\",\n",
    "                \"difficulty\": \"pc\",\n",
    "            },\n",
    "            {\n",
    "                \"model_type\": config.IRTModelType.WRC,\n",
    "                \"ability\": \"mean\",\n",
    "                \"ab_int\": 3,\n",
    "                \"difficulty\": \"pc\",\n",
    "            },\n",
    "            {\n",
    "                \"model_type\": config.IRTModelType.WRC,\n",
    "                \"ability\": \"elo\",\n",
    "                \"difficulty\": \"elo\",\n",
    "                \"W\": 0.2,\n",
    "            },\n",
    "            {\n",
    "                \"model_type\": config.IRTModelType.WRC,\n",
    "                \"ability\": \"elo\",\n",
    "                \"difficulty\": \"elo\",\n",
    "                \"W\": 0.4,\n",
    "            },\n",
    "            {\n",
    "                \"model_type\": config.IRTModelType.WRC,\n",
    "                \"ability\": \"elo\",\n",
    "                \"difficulty\": \"elo\",\n",
    "                \"W\": 0.6,\n",
    "            },\n",
    "        ],\n",
    "        \"saving_file\": {\n",
    "            \"folder\": \"item_response_theory\",\n",
    "            \"filename\": \"version4\",\n",
    "            \"filename_suffix\": filename_suffix,\n",
    "        },\n",
    "    }\n",
    "\n",
    "save_file = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2rc = c2rc_part1.copy()\n",
    "df = df_orig.copy()\n",
    "\n",
    "conf = get_conf_version4(filename_suffix=\"part1\")\n",
    "\n",
    "# check validity of conf dictionary\n",
    "training_general.check_conf(conf, save_file=save_file)\n",
    "\n",
    "with_rc = conf[\"with_ref_class\"]\n",
    "\n",
    "# create dataframes\n",
    "df, ass_seq, stud_per_class = training_general.create_dataframes(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty evaluation dataframe for complete training\n",
    "if with_rc:\n",
    "    index = training_with_rc.get_idx_pred_df(c2rc)\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "pred_df = training_general.initialize_pred_df(index=index, conf=conf)\n",
    "\n",
    "\n",
    "count = 0\n",
    "#count = 320\n",
    "for cid, cid_dict in c2rc.items():\n",
    "#for cid, cid_dict in list(c2rc.items())[:1]:\n",
    "#for cid in [\"2JFV80TTBO\"]:\n",
    "    #cid_dict = c2rc[cid]\n",
    "    #print(f\"----------- Class {cid} ------------\")\n",
    "\n",
    "    # make predictions for cid, evaluate and store evaluation results\n",
    "    if with_rc:\n",
    "        pred_df.loc[cid] = (\n",
    "            training_with_rc.perform_predictions_for_cid(\n",
    "                conf, cid, cid_dict, df, ass_seq, stud_per_class\n",
    "            )\n",
    "            .reindex(pred_df.loc[cid].index)\n",
    "            .to_numpy()\n",
    "        )\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    count += 1\n",
    "    if count % 10 == 0:\n",
    "        d = datetime.datetime.now()\n",
    "        print(f\"{count} classes completed, last cid: {cid}, time: {d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows only containing nans\n",
    "pred_df = pred_df.dropna(subset=[\"y_true\"])\n",
    "print(len(pred_df))\n",
    "pred_df1 = pred_df.copy()\n",
    "\n",
    "# save\n",
    "utils.save_predictions(pred_df, conf, save_idx=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pred_df1.copy()\n",
    "# evaluate predictions and save\n",
    "training_general.evaluate_predictions_and_save(pred_df, conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2rc = c2rc_part2.copy()\n",
    "df = df_orig.copy()\n",
    "\n",
    "conf = get_conf_version4(filename_suffix=\"part2\")\n",
    "\n",
    "# check validity of conf dictionary\n",
    "training_general.check_conf(conf, save_file=save_file)\n",
    "\n",
    "with_rc = conf[\"with_ref_class\"]\n",
    "\n",
    "# create dataframes\n",
    "df, ass_seq, stud_per_class = training_general.create_dataframes(df)\n",
    "\n",
    "# create empty evaluation dataframe for complete training\n",
    "if with_rc:\n",
    "    index = training_with_rc.get_idx_pred_df(c2rc)\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "pred_df = training_general.initialize_pred_df(index=index, conf=conf)\n",
    "\n",
    "\n",
    "count = 0\n",
    "#count = 320\n",
    "for cid, cid_dict in c2rc.items():\n",
    "#for cid, cid_dict in list(c2rc.items())[:3]:\n",
    "#for cid in [\"ODWI4QBKV\"]:\n",
    "    #cid_dict = c2rc[cid]\n",
    "    #print(f\"----------- Class {cid} ------------\")\n",
    "\n",
    "    # make predictions for cid, evaluate and store evaluation results\n",
    "    if with_rc:\n",
    "        pred_df.loc[cid] = (\n",
    "            training_with_rc.perform_predictions_for_cid(\n",
    "                conf, cid, cid_dict, df, ass_seq, stud_per_class\n",
    "            )\n",
    "            .reindex(pred_df.loc[cid].index)\n",
    "            .to_numpy()\n",
    "        )\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    count += 1\n",
    "    if count % 10 == 0:\n",
    "        d = datetime.datetime.now()\n",
    "        print(f\"{count} classes completed, last cid: {cid}, time: {d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows only containing nans\n",
    "pred_df = pred_df.dropna(subset=[\"y_true\"])\n",
    "print(len(pred_df))\n",
    "pred_df2 = pred_df.copy()\n",
    "\n",
    "# save\n",
    "utils.save_predictions(pred_df, conf, save_idx=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pred_df2.copy()\n",
    "# evaluate predictions and save\n",
    "training_general.evaluate_predictions_and_save(pred_df, conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2rc = c2rc_part3.copy()\n",
    "df = df_orig.copy()\n",
    "\n",
    "conf = get_conf_version4(filename_suffix=\"part3\")\n",
    "\n",
    "# check validity of conf dictionary\n",
    "training_general.check_conf(conf, save_file=save_file)\n",
    "\n",
    "with_rc = conf[\"with_ref_class\"]\n",
    "\n",
    "# create dataframes\n",
    "df, ass_seq, stud_per_class = training_general.create_dataframes(df)\n",
    "\n",
    "# create empty evaluation dataframe for complete training\n",
    "if with_rc:\n",
    "    index = training_with_rc.get_idx_pred_df(c2rc)\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "pred_df = training_general.initialize_pred_df(index=index, conf=conf)\n",
    "\n",
    "\n",
    "count = 0\n",
    "#count = 320\n",
    "for cid, cid_dict in c2rc.items():\n",
    "#for cid, cid_dict in list(c2rc.items())[:3]:\n",
    "#for cid in [\"ODWI4QBKV\"]:\n",
    "    #cid_dict = c2rc[cid]\n",
    "    #print(f\"----------- Class {cid} ------------\")\n",
    "\n",
    "    # make predictions for cid, evaluate and store evaluation results\n",
    "    if with_rc:\n",
    "        pred_df.loc[cid] = (\n",
    "            training_with_rc.perform_predictions_for_cid(\n",
    "                conf, cid, cid_dict, df, ass_seq, stud_per_class\n",
    "            )\n",
    "            .reindex(pred_df.loc[cid].index)\n",
    "            .to_numpy()\n",
    "        )\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    count += 1\n",
    "    if count % 10 == 0:\n",
    "        d = datetime.datetime.now()\n",
    "        print(f\"{count} classes completed, last cid: {cid}, time: {d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows only containing nans\n",
    "pred_df = pred_df.dropna(subset=[\"y_true\"])\n",
    "print(len(pred_df))\n",
    "pred_df3 = pred_df.copy()\n",
    "\n",
    "# save\n",
    "utils.save_predictions(pred_df, conf, save_idx=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pred_df3.copy()\n",
    "# evaluate predictions and save\n",
    "training_general.evaluate_predictions_and_save(pred_df, conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Part 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2rc = c2rc_part4.copy()\n",
    "df = df_orig.copy()\n",
    "\n",
    "conf = get_conf_version4(filename_suffix=\"part4\")\n",
    "\n",
    "# check validity of conf dictionary\n",
    "training_general.check_conf(conf, save_file=save_file)\n",
    "\n",
    "with_rc = conf[\"with_ref_class\"]\n",
    "\n",
    "# create dataframes\n",
    "df, ass_seq, stud_per_class = training_general.create_dataframes(df)\n",
    "\n",
    "# create empty evaluation dataframe for complete training\n",
    "if with_rc:\n",
    "    index = training_with_rc.get_idx_pred_df(c2rc)\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "pred_df = training_general.initialize_pred_df(index=index, conf=conf)\n",
    "\n",
    "\n",
    "count = 0\n",
    "#count = 320\n",
    "for cid, cid_dict in c2rc.items():\n",
    "#for cid, cid_dict in list(c2rc.items())[:3]:\n",
    "#for cid in [\"ODWI4QBKV\"]:\n",
    "    #cid_dict = c2rc[cid]\n",
    "    #print(f\"----------- Class {cid} ------------\")\n",
    "\n",
    "    # make predictions for cid, evaluate and store evaluation results\n",
    "    if with_rc:\n",
    "        pred_df.loc[cid] = (\n",
    "            training_with_rc.perform_predictions_for_cid(\n",
    "                conf, cid, cid_dict, df, ass_seq, stud_per_class\n",
    "            )\n",
    "            .reindex(pred_df.loc[cid].index)\n",
    "            .to_numpy()\n",
    "        )\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    count += 1\n",
    "    if count % 10 == 0:\n",
    "        d = datetime.datetime.now()\n",
    "        print(f\"{count} classes completed, last cid: {cid}, time: {d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows only containing nans\n",
    "pred_df = pred_df.dropna(subset=[\"y_true\"])\n",
    "print(len(pred_df))\n",
    "pred_df4 = pred_df.copy()\n",
    "\n",
    "# save\n",
    "utils.save_predictions(pred_df, conf, save_idx=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pred_df4.copy()\n",
    "# evaluate predictions and save\n",
    "training_general.evaluate_predictions_and_save(pred_df, conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run 3: py-irt --> restricted random reference classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conf_version3(filename_suffix: str) -> dict:\n",
    "    return {\n",
    "        \"lim\": [0.3, 0.5, 0.7, config.LimType.DYNAMIC],\n",
    "        \"eval_groups\": [\"info_cols\", \"reg_metrics\", \"class_metrics\"],\n",
    "        \"reg_metrics\": [config.RegMetrics.MAE, config.RegMetrics.MSE],\n",
    "        \"class_metrics\": [\n",
    "            config.ClassMetrics.ACC,\n",
    "            config.ClassMetrics.F1,\n",
    "            config.ClassMetrics.PREC,\n",
    "            config.ClassMetrics.REC,\n",
    "        ],\n",
    "        \"info_cols\": [\n",
    "            config.InfoCols.NUM_UT_PROBS,\n",
    "            config.InfoCols.NUM_IU_PROBS,\n",
    "            config.InfoCols.MEAN_UT_PERF,\n",
    "            config.InfoCols.MEAN_IU_PERF,\n",
    "            config.InfoCols.NUM_STUD_RC,\n",
    "            config.InfoCols.MAX_NUM_IU_PROBS_RC,\n",
    "            config.InfoCols.MEAN_IU_PERF_RC,\n",
    "            config.InfoCols.MEAN_UT_PERF_RC\n",
    "        ],\n",
    "        \"method\": config.RecMethod.IRT,\n",
    "        \"with_ref_class\": True,\n",
    "        \"models\": [\n",
    "            {\n",
    "                \"model_type\": config.IRTModelType.WRC,\n",
    "                \"ability\": \"package\",\n",
    "                \"difficulty\": \"1pl\"\n",
    "            },\n",
    "            {\n",
    "                \"model_type\": config.IRTModelType.WRC,\n",
    "                \"ability\": \"package\",\n",
    "                \"difficulty\": \"2pl\"\n",
    "            }\n",
    "        ],\n",
    "        \"saving_file\": {\n",
    "            \"folder\": \"item_response_theory\",\n",
    "            \"filename\": \"version3\",\n",
    "            \"filename_suffix\": filename_suffix,\n",
    "        },\n",
    "    }\n",
    "\n",
    "save_file = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2rc = c2rc_part1.copy()\n",
    "df = df_orig.copy()\n",
    "\n",
    "conf = get_conf_version3(filename_suffix=\"part1\")\n",
    "\n",
    "# check validity of conf dictionary\n",
    "training_general.check_conf(conf, save_file=save_file)\n",
    "\n",
    "with_rc = conf[\"with_ref_class\"]\n",
    "\n",
    "# create dataframes\n",
    "df, ass_seq, stud_per_class = training_general.create_dataframes(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty evaluation dataframe for complete training\n",
    "if with_rc:\n",
    "    index = training_with_rc.get_idx_pred_df(c2rc)\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "pred_df = training_general.initialize_pred_df(index=index, conf=conf)\n",
    "\n",
    "\n",
    "count = 0\n",
    "for cid, cid_dict in c2rc.items():\n",
    "#for cid, cid_dict in list(c2rc.items())[:10]:\n",
    "#for cid in [\"2JFV80TTBO\"]:\n",
    "    #cid_dict = c2rc[cid]\n",
    "    #print(f\"----------- Class {cid} ------------\")\n",
    "\n",
    "    # make predictions for cid, evaluate and store evaluation results\n",
    "    if with_rc:\n",
    "        pred_df.loc[cid] = (\n",
    "            training_with_rc.perform_predictions_for_cid(\n",
    "                conf, cid, cid_dict, df, ass_seq, stud_per_class\n",
    "            )\n",
    "            .reindex(pred_df.loc[cid].index)\n",
    "            .to_numpy()\n",
    "        )\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    count += 1\n",
    "    if count % 10 == 0:\n",
    "        d = datetime.datetime.now()\n",
    "        print(f\"{count} classes completed, last cid: {cid}, time: {d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows only containing nans\n",
    "pred_df = pred_df.dropna(subset=[\"y_true\"])\n",
    "print(len(pred_df))\n",
    "pred_df1 = pred_df.copy()\n",
    "\n",
    "# save\n",
    "utils.save_predictions(pred_df, conf, save_idx=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pred_df1.copy()\n",
    "# evaluate predictions and save\n",
    "training_general.evaluate_predictions_and_save(pred_df, conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2rc = c2rc_part2.copy()\n",
    "df = df_orig.copy()\n",
    "\n",
    "conf = get_conf_version3(filename_suffix=\"part2\")\n",
    "\n",
    "# check validity of conf dictionary\n",
    "training_general.check_conf(conf, save_file=save_file)\n",
    "\n",
    "with_rc = conf[\"with_ref_class\"]\n",
    "\n",
    "# create dataframes\n",
    "df, ass_seq, stud_per_class = training_general.create_dataframes(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty evaluation dataframe for complete training\n",
    "if with_rc:\n",
    "    index = training_with_rc.get_idx_pred_df(c2rc)\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "pred_df = training_general.initialize_pred_df(index=index, conf=conf)\n",
    "\n",
    "\n",
    "count = 0\n",
    "for cid, cid_dict in c2rc.items():\n",
    "#for cid, cid_dict in list(c2rc.items())[:10]:\n",
    "#for cid in [\"14MZLGKL6K\"]:\n",
    "    #cid_dict = c2rc[cid]\n",
    "    #print(f\"----------- Class {cid} ------------\")\n",
    "\n",
    "    # make predictions for cid, evaluate and store evaluation results\n",
    "    if with_rc:\n",
    "        pred_df.loc[cid] = (\n",
    "            training_with_rc.perform_predictions_for_cid(\n",
    "                conf, cid, cid_dict, df, ass_seq, stud_per_class\n",
    "            )\n",
    "            .reindex(pred_df.loc[cid].index)\n",
    "            .to_numpy()\n",
    "        )\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    count += 1\n",
    "    if count % 10 == 0:\n",
    "        d = datetime.datetime.now()\n",
    "        print(f\"{count} classes completed, last cid: {cid}, time: {d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows only containing nans\n",
    "pred_df = pred_df.dropna(subset=[\"y_true\"])\n",
    "print(len(pred_df))\n",
    "pred_df2 = pred_df.copy()\n",
    "\n",
    "# save\n",
    "utils.save_predictions(pred_df, conf, save_idx=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pred_df2.copy()\n",
    "# evaluate predictions and save\n",
    "training_general.evaluate_predictions_and_save(pred_df, conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2rc = c2rc_part3.copy()\n",
    "df = df_orig.copy()\n",
    "\n",
    "conf = get_conf_version3(filename_suffix=\"part3\")\n",
    "\n",
    "# check validity of conf dictionary\n",
    "training_general.check_conf(conf, save_file=save_file)\n",
    "\n",
    "with_rc = conf[\"with_ref_class\"]\n",
    "\n",
    "# create dataframes\n",
    "df, ass_seq, stud_per_class = training_general.create_dataframes(df)\n",
    "\n",
    "# create empty evaluation dataframe for complete training\n",
    "if with_rc:\n",
    "    index = training_with_rc.get_idx_pred_df(c2rc)\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "pred_df = training_general.initialize_pred_df(index=index, conf=conf)\n",
    "\n",
    "\n",
    "count = 0\n",
    "for cid, cid_dict in c2rc.items():\n",
    "#for cid, cid_dict in list(c2rc.items())[:10]:\n",
    "#for cid in [\"ODWI4QBKV\"]:\n",
    "    #cid_dict = c2rc[cid]\n",
    "    #print(f\"----------- Class {cid} ------------\")\n",
    "\n",
    "    # make predictions for cid, evaluate and store evaluation results\n",
    "    if with_rc:\n",
    "        pred_df.loc[cid] = (\n",
    "            training_with_rc.perform_predictions_for_cid(\n",
    "                conf, cid, cid_dict, df, ass_seq, stud_per_class\n",
    "            )\n",
    "            .reindex(pred_df.loc[cid].index)\n",
    "            .to_numpy()\n",
    "        )\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    count += 1\n",
    "    if count % 10 == 0:\n",
    "        d = datetime.datetime.now()\n",
    "        print(f\"{count} classes completed, last cid: {cid}, time: {d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows only containing nans\n",
    "pred_df = pred_df.dropna(subset=[\"y_true\"])\n",
    "print(len(pred_df))\n",
    "pred_df3 = pred_df.copy()\n",
    "\n",
    "# save\n",
    "utils.save_predictions(pred_df, conf, save_idx=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pred_df3.copy()\n",
    "# evaluate predictions and save\n",
    "training_general.evaluate_predictions_and_save(pred_df, conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Part 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2rc = c2rc_part4.copy()\n",
    "df = df_orig.copy()\n",
    "\n",
    "conf = get_conf_version3(filename_suffix=\"part4\")\n",
    "\n",
    "# check validity of conf dictionary\n",
    "training_general.check_conf(conf, save_file=save_file)\n",
    "\n",
    "with_rc = conf[\"with_ref_class\"]\n",
    "\n",
    "# create dataframes\n",
    "df, ass_seq, stud_per_class = training_general.create_dataframes(df)\n",
    "\n",
    "# create empty evaluation dataframe for complete training\n",
    "if with_rc:\n",
    "    index = training_with_rc.get_idx_pred_df(c2rc)\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "pred_df = training_general.initialize_pred_df(index=index, conf=conf)\n",
    "\n",
    "\n",
    "count = 0\n",
    "for cid, cid_dict in c2rc.items():\n",
    "#for cid, cid_dict in list(c2rc.items())[:10]:\n",
    "#for cid in [\"ODWI4QBKV\"]:\n",
    "    #cid_dict = c2rc[cid]\n",
    "    #print(f\"----------- Class {cid} ------------\")\n",
    "\n",
    "    # make predictions for cid, evaluate and store evaluation results\n",
    "    if with_rc:\n",
    "        pred_df.loc[cid] = (\n",
    "            training_with_rc.perform_predictions_for_cid(\n",
    "                conf, cid, cid_dict, df, ass_seq, stud_per_class\n",
    "            )\n",
    "            .reindex(pred_df.loc[cid].index)\n",
    "            .to_numpy()\n",
    "        )\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    count += 1\n",
    "    if count % 10 == 0:\n",
    "        d = datetime.datetime.now()\n",
    "        print(f\"{count} classes completed, last cid: {cid}, time: {d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows only containing nans\n",
    "pred_df = pred_df.dropna(subset=[\"y_true\"])\n",
    "print(len(pred_df))\n",
    "pred_df4 = pred_df.copy()\n",
    "\n",
    "# save\n",
    "utils.save_predictions(pred_df, conf, save_idx=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pred_df4.copy()\n",
    "# evaluate predictions and save\n",
    "training_general.evaluate_predictions_and_save(pred_df, conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WITHOUT REFERENCE CLASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "df = utils.read_data_file(\"final_data_main_approach.csv\")\n",
    "df_orig = df.copy()\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version 2: Without Reference Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conf_version2(filename_suffix: str) -> dict:\n",
    "    return {\n",
    "        \"lim\": [0.3, 0.5, 0.7, config.LimType.DYNAMIC],\n",
    "        \"eval_groups\": [\"info_cols\", \"reg_metrics\", \"class_metrics\"],\n",
    "        \"reg_metrics\": [config.RegMetrics.MAE, config.RegMetrics.MSE],\n",
    "        \"class_metrics\": [\n",
    "            config.ClassMetrics.ACC,\n",
    "            config.ClassMetrics.F1,\n",
    "            config.ClassMetrics.PREC,\n",
    "            config.ClassMetrics.REC,\n",
    "        ],\n",
    "        \"info_cols\": [\n",
    "            config.InfoCols.NUM_UT_PROBS,\n",
    "            config.InfoCols.NUM_IU_PROBS,\n",
    "            config.InfoCols.MEAN_UT_PERF,\n",
    "            config.InfoCols.MEAN_IU_PERF,\n",
    "        ],\n",
    "        \"method\": config.RecMethod.IRT,\n",
    "        \"with_ref_class\": False,\n",
    "        \"models\": [\n",
    "            {\n",
    "                \"model_type\": config.IRTModelType.WORC,\n",
    "                \"ability\": \"mean\",\n",
    "                \"difficulty\": \"expert\",\n",
    "            },\n",
    "            {\n",
    "                \"model_type\": config.IRTModelType.WORC,\n",
    "                \"ability\": \"mean\",\n",
    "                \"ab_int\": 3,\n",
    "                \"difficulty\": \"expert\",\n",
    "                \"diff_int\": 3,\n",
    "            },\n",
    "            {\n",
    "                \"model_type\": config.IRTModelType.WORC,\n",
    "                \"ability\": \"mean\",\n",
    "                \"difficulty\": \"expert\",\n",
    "                \"diff_int\": 3,\n",
    "            },\n",
    "            {\n",
    "                \"model_type\": config.IRTModelType.WORC,\n",
    "                \"ability\": \"mean\",\n",
    "                \"ab_int\": 3,\n",
    "                \"difficulty\": \"expert\",\n",
    "            },\n",
    "        ],\n",
    "        \"saving_file\": {\n",
    "            \"folder\": \"item_response_theory\",\n",
    "            \"filename\": \"version2\",\n",
    "            \"filename_suffix\": filename_suffix,\n",
    "        },\n",
    "    }\n",
    "\n",
    "save_file = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = get_conf_version2(filename_suffix=\"\")\n",
    "\n",
    "df = df_orig.copy()\n",
    "\n",
    "# check validity of conf dictionary\n",
    "training_general.check_conf(conf, save_file=save_file)\n",
    "\n",
    "with_rc = conf[\"with_ref_class\"]\n",
    "\n",
    "# get dictionary with reference classes\n",
    "class_to_reference_class = determine_reference_classes.get_reference_classes(df)\n",
    "print(len(class_to_reference_class))\n",
    "# it is not used for the reference classes but to know which classes and test sequences are evaluated\n",
    "\n",
    "# create dataframes\n",
    "df, ass_seq, _ = training_general.create_dataframes(df)\n",
    "\n",
    "# create empty evaluation dataframe for complete training\n",
    "if with_rc:\n",
    "    raise NotImplementedError\n",
    "else:\n",
    "    index = training_without_rc.get_idx_pred_df(class_to_reference_class)\n",
    "pred_df = training_general.initialize_pred_df(index=index, conf=conf)\n",
    "\n",
    "\n",
    "count = 0\n",
    "#count = 320\n",
    "for cid, cid_dict in class_to_reference_class.items():\n",
    "#for cid, cid_dict in list(class_to_reference_class.items())[:2]:\n",
    "#for cid in [\"2JFV80TTBO\"]:\n",
    "    #cid_dict = class_to_reference_class[cid]\n",
    "    #print(f\"----------- Class {cid} ------------\")\n",
    "\n",
    "    # make predictions for cid, evaluate and store evaluation results\n",
    "    if with_rc:\n",
    "        pred_df.loc[cid] = (\n",
    "            training_with_rc.perform_predictions_for_cid(\n",
    "                conf, cid, cid_dict, df, ass_seq, stud_per_class\n",
    "            )\n",
    "            .reindex(pred_df.loc[cid].index)\n",
    "            .to_numpy()\n",
    "        )\n",
    "    else:\n",
    "        pred_df.loc[cid] = (\n",
    "            training_without_rc.perform_predictions_for_cid(\n",
    "                conf, cid, cid_dict, df, ass_seq\n",
    "            )\n",
    "            .reindex(pred_df.loc[cid].index)\n",
    "            .to_numpy()\n",
    "        )\n",
    "\n",
    "    count += 1\n",
    "    if count % 10 == 0:\n",
    "        d = datetime.datetime.now()\n",
    "        print(f\"{count} classes completed, last cid: {cid}, time: {d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows only containing nans\n",
    "pred_df = pred_df.dropna(subset=[\"y_true\"])\n",
    "print(len(pred_df))\n",
    "pred_df_wo = pred_df.copy()\n",
    "\n",
    "# save\n",
    "utils.save_predictions(pred_df, conf, save_idx=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pred_df_wo.copy()\n",
    "# evaluate predictions and save\n",
    "training_general.evaluate_predictions_and_save(pred_df, conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
